{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 27 марта 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 27 марта, -4 балла после 06:00 3 апреля, -6 баллов после 06:00 10 апреля\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw2.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (2 баллов)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. В комментариях, где написано \"Что делает этот блок кода?\", ответьте на этот вопрос. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (2 балла)\n",
    "Добиться скорости работы на fit сравнимой со sklearn wine и Speed Dating Data. \n",
    "Для этого используем numpy. \n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Продемонстрируйте умение работать с Pipeline на данных Speed Dating Data и DecisionTreeClassifier. Нужно в pipeline произвести все необходимые преобразования данных и в конце обучить модель. Задание реализуйте под пунктом Задание 3 (уже написано ниже)\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 5 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# %matplotlib inline\n",
    "# %load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "            self.single_G_function = self.__single_gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "            self.single_G_function = self.__single_entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "            self.single_G_function = self.__single_misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype(np.float)\n",
    "        r_s = r_s.astype(np.float)\n",
    "        return l_s * (1 - np.sum((l_c / l_s) ** 2, axis=1)[:, np.newaxis]) + r_s * (1 - np.sum((r_c / r_s) ** 2, axis=1)[:, np.newaxis])\n",
    "    \n",
    "    def __single_gini(self, y):\n",
    "        counts = np.unique(y, return_counts=True)[1]\n",
    "        return y.size * (1 - np.sum((counts / y.size) ** 2))\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype(np.float)\n",
    "        r_s = r_s.astype(np.float)\n",
    "        return -l_s * np.sum(l_c / l_s * np.log2(l_c / l_s), axis=1)[:, np.newaxis] - r_s * np.sum(r_c / r_s * np.log2(r_c / r_s), axis=1)[:, np.newaxis]\n",
    "\n",
    "    def __single_entropy(self, y):\n",
    "        counts = np.unique(y, return_counts=True)[1]\n",
    "        return -y.size * np.sum((counts / y.size) * np.log2(counts / y.size))\n",
    "    \n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype(np.float)\n",
    "        r_s = r_s.astype(np.float)\n",
    "        return l_s * (1 - np.max(l_c / l_s, axis=1)[:, np.newaxis]) + r_s * (1 - np.max(r_c / r_s, axis=1)[:, np.newaxis])\n",
    "    \n",
    "    def __single_misclass(self, y):\n",
    "        counts = np.unique(y, return_counts=True)[1]\n",
    "        return y.size * (1 - np.max(counts / y.size))\n",
    "    \n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(sqrt(n_feature))]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(log2(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return range(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y) # Сортируем строки данных по признаку x\n",
    "        #class_number = np.unique(y).shape[0] # Запоминаем кол-во уникальных значений целевой переменной\n",
    "        class_number = self.num_class\n",
    "        \n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = self.num_class\n",
    "        \n",
    "        cut_size = np.int(self.min_samples_split / 2 - 1)        \n",
    "        if cut_size == 0:\n",
    "            splitted_sorted_y = sorted_y\n",
    "        else:\n",
    "            splitted_sorted_y = sorted_y[cut_size:-cut_size] # Вырезаем часть столбца целевой переменной\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (cut_size + 1) # запоминаем индексы несовпадений\n",
    "        # запоминаем в пределах этого выреза индексы тех значений целевой переменной, которые отличаются от предыдущего значения \n",
    "        # целевой переменной     \n",
    "        \n",
    "        # в качестве порогов для \"нарезания\" количественного признака, \n",
    "        # дерево должно\"смотреть\" на те значения, при которых целевой класс меняет свое значение.  \n",
    "        if len(r_border_ids) == 0:\n",
    "            return np.inf, None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        eq_el_count = r_border_ids - np.append(np.array([cut_size]), r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:cut_size], minlength=class_number)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)     # формируется матрица, размера: \n",
    "        # число значений целевой переменной на число разбиений, у которой каждая строка - число сэмплов с левой стороны разбиения\n",
    "        # c таким-то значением целевой переменной (например если при первом разбиении слева оказались 3 единицы и два нуля, то \n",
    "        # первая строка этой матрицы - [2 3] и т.д.)\n",
    "        r_class_count = np.bincount(sorted_y, minlength=class_number) - l_class_count\n",
    "        # то же самое, но справа от разбиения\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        # число элементов слева от разбиения в сумме\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "        # число элементов справа от разбиения в сумме\n",
    "        \n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes) \n",
    "        # Находим impurity в соответствии с выбранной функцией оценки приращения информации (энтропия, gini_index и т.д.)\n",
    "        idx = np.argmin(gs)\n",
    "        # Запоминаем индекс лучшего разбиения\n",
    "    \n",
    "        # Что делает этот блок кода?\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0 \n",
    "        \n",
    "        # Первое возвращаем значение - индекс лучшего разбиения\n",
    "        # Второе возвращаемое значение - все границы, полученные как среднее между теми двумя признаками, при проходе через которые\n",
    "        # целевая переменная меняет свое значение\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1): \n",
    "        if depth == self.max_depth or x.shape[0] < self.min_samples_split or np.unique(y).shape[0] == 1:\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.bincount(y).argmax())\n",
    "            return             \n",
    "        \n",
    "        features_threshold = np.zeros(x.shape[1])\n",
    "        features_impurity = np.zeros(x.shape[1])\n",
    "        \n",
    "        for feature_id in self.get_feature_ids(x.shape[1]):\n",
    "            features_impurity[feature_id], features_threshold[feature_id] = self.__find_threshold(x[:,feature_id],y)\n",
    "            if feature_id == pred_f:\n",
    "                features_threshold[feature_id] = np.inf\n",
    "        \n",
    "        feature_id = np.argmin(features_impurity)\n",
    "        \n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, feature_id, features_threshold[feature_id])\n",
    "        \n",
    "        if y_l.shape[0] == 0 or y_r.shape[0] == 0:\n",
    "            self.__create_leaf(y,node_id)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE,feature_id,features_threshold[feature_id])\n",
    "        self.feature_importances_[feature_id] += self.single_G_function(y) - self.single_G_function(y_l) - self.single_G_function(y_r)\n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1, feature_id)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1, feature_id)\n",
    "        \n",
    "    def __create_leaf(self, y, node_id):  \n",
    "        counts = np.bincount(y, minlength=self.num_class)\n",
    "        probs = counts / np.sum(counts).astype('float')\n",
    "        self.tree[node_id] = (self.LEAF_TYPE, np.argmax(counts), probs)        \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "        self.feature_importances_ /= y.size\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    def score(self, x,y_test):\n",
    "        return f1_score(y_pred=my_clf.predict(x), y_true=y_test, average='macro')\n",
    "    def tree(self):\n",
    "        tr = np.copy(self.tree)\n",
    "        return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77777777777777768"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77777777777777768"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Field Code 1.0\n",
      "['Law' 'law' 'LAW' 'Law and Social Work'\n",
      " 'Law and English Literature (J.D./Ph.D.)' 'Intellectual Property Law'\n",
      " 'Law/Business']\n",
      "==========\n",
      "Field Code 2.0\n",
      "['Economics' 'Mathematics' 'Statistics' 'math' 'Mathematics, PhD' 'Stats'\n",
      " 'math of finance' 'Math']\n",
      "==========\n",
      "Field Code 3.0\n",
      "['Psychology' 'Speech Language Pathology' 'Speech Languahe Pathology'\n",
      " 'Educational Psychology' 'Organizational Psychology' 'psychology'\n",
      " 'Communications' 'Sociology' 'psychology and english' 'theory'\n",
      " 'Health policy' 'Clinical Psychology' 'Sociology and Education'\n",
      " 'sociology' 'Anthropology/Education' 'speech pathology' 'Speech Pathology'\n",
      " 'Anthropology' 'School Psychology' 'anthropology' 'Counseling Psychology'\n",
      " 'African-American Studies/History']\n",
      "==========\n",
      "Field Code 4.0\n",
      "['Medicine' 'Art History/medicine'\n",
      " 'Sociomedical Sciences- School of Public Health' 'Epidemiology'\n",
      " 'GS Postbacc PreMed' 'medicine']\n",
      "==========\n",
      "Field Code 5.0\n",
      "['Operations Research' 'Mechanical Engineering' 'Engineering'\n",
      " 'Electrical Engineering' 'Operations Research (SEAS)'\n",
      " 'Education Administration' 'Computer Science' 'Biomedical Engineering'\n",
      " 'electrical engineering' 'engineering' 'Medical Informatics'\n",
      " 'medical informatics' 'Electrical Engg.' 'Environmental Engineering'\n",
      " 'Instructional Tech & Media' 'MA in Quantitative Methods' 'Urban Planning'\n",
      " 'Financial Engineering' 'biomedical engineering' 'biomedical informatics'\n",
      " 'ELECTRICAL ENGINEERING' 'Biomedical engineering' 'Industrial Engineering'\n",
      " 'Industrial Engineering/Operations Research'\n",
      " 'Masters of Industrial Engineering' 'Biomedical Informatics']\n",
      "==========\n",
      "Field Code 6.0\n",
      "['MFA Creative Writing' 'Classics' 'Journalism' 'English'\n",
      " 'Comparative Literature' 'English and Comp Lit'\n",
      " 'Communications in Education' 'Creative Writing'\n",
      " 'Creative Writing - Nonfiction' 'Writing: Literary Nonfiction'\n",
      " 'Creative Writing (Nonfiction)' 'NonFiction Writing' 'SOA -- writing'\n",
      " 'journalism' 'Nonfiction writing']\n",
      "==========\n",
      "Field Code 7.0\n",
      "['German Literature' 'Religion' 'philosophy' 'History of Religion'\n",
      " 'Modern Chinese Literature' 'Philosophy' 'Religion, GSAS' 'History'\n",
      " 'History (GSAS - PhD)' 'American Studies' 'Philosophy (Ph.D.)'\n",
      " 'Philosophy and Physics' 'Art History' 'art history']\n",
      "==========\n",
      "Field Code 8.0\n",
      "['Finance' 'Business' 'money' 'Applied Maths/Econs' 'Economics' 'Finanace'\n",
      " 'Finance&Economics' 'Mathematical Finance' 'MBA'\n",
      " 'Business & International Affairs' 'Marketing' 'Business (MBA)'\n",
      " 'financial math' 'Business- MBA' 'Economics, English'\n",
      " 'Economics, Sociology' 'Economics and Political Science' 'business'\n",
      " 'Business, marketing' 'Business/ Finance/ Real Estate'\n",
      " 'International Affairs/Finance' 'international finance and business'\n",
      " 'International Business' 'International Finance, Economic Policy'\n",
      " 'Business/Law' 'Business and International Affairs (MBA/MIA Dual Degree)'\n",
      " 'QMSS' 'Public Administration' 'Master in Public Administration'\n",
      " 'Business School' 'MBA / Master of International Affairs (SIPA)'\n",
      " 'Finance/Economics' 'Business Administration' 'MBA Finance'\n",
      " 'BUSINESS CONSULTING' 'business school' 'Business, Media'\n",
      " 'Fundraising Management' 'Business (Finance & Marketing)' 'Consulting'\n",
      " 'MBA - Private Equity / Real Estate' 'General management/finance']\n",
      "==========\n",
      "Field Code 9.0\n",
      "['TC (Health Ed)' 'Elementary/Childhood Education (MA)'\n",
      " 'International Educational Development' 'Art Education'\n",
      " 'elementary education' 'MA Science Education' 'Social Studies Education'\n",
      " 'MA Teaching Social Studies' 'Education Policy'\n",
      " 'Education- Literacy Specialist' 'bilingual education' 'Education'\n",
      " 'math education' 'TESOL' 'Elementary Education'\n",
      " 'Cognitive Studies in Education' 'education'\n",
      " 'Curriculum and Teaching/Giftedness' 'Instructional Media and Technology'\n",
      " 'English Education' 'art education' 'Early Childhood Education'\n",
      " 'Ed.D. in higher education policy at TC' 'EDUCATION' 'music education'\n",
      " 'Music Education' 'Higher Ed. - M.A.' 'Neuroscience and Education'\n",
      " 'Elementary Education - Preservice'\n",
      " 'Education Leadership - Public School Administration'\n",
      " 'Bilingual Education' 'teaching of English']\n",
      "==========\n",
      "Field Code 10.0\n",
      "['chemistry' 'microbiology' 'Chemistry'\n",
      " 'Climate-Earth and Environ. Science' 'marine geophysics'\n",
      " 'Nutrition/Genetics' 'Neuroscience' 'physics (astrophysics)' 'Physics'\n",
      " 'Biochemistry' 'biology' 'Cell Biology' 'Microbiology' 'climate change'\n",
      " 'MA Biotechnology' 'Ecology' 'Computational Biochemsistry' 'Neurobiology'\n",
      " 'biomedicine' 'Biology' 'Conservation biology' 'biotechnology'\n",
      " 'Earth and Environmental Science' 'nutrition' 'Genetics' 'Nutritiron'\n",
      " 'Molecular Biology' 'Genetics & Development' 'genetics'\n",
      " 'medicine and biochemistry' 'Epidemiology' 'Nutrition'\n",
      " 'Applied Physiology & Nutrition' 'Biomedical Engineering' 'physics'\n",
      " 'Biotechnology' 'Neurosciences/Stem cells' 'Biology PhD'\n",
      " 'biochemistry/genetics' 'epidemiology'\n",
      " 'Biochemistry & Molecular Biophysics']\n",
      "==========\n",
      "Field Code 11.0\n",
      "['social work' 'Social Work' 'Masters of Social Work' 'Social work'\n",
      " 'International Affairs' 'Social Work/SIPA']\n",
      "==========\n",
      "Field Code 12.0\n",
      "['Undergrad - GS']\n",
      "==========\n",
      "Field Code 13.0\n",
      "['Masters in Public Administration' 'Masters of Social Work&Education'\n",
      " 'political science' 'International Relations'\n",
      " 'international affairs - economic development' 'Political Science'\n",
      " 'American Studies (Masters)' 'International Affairs'\n",
      " 'international affairs/international finance' 'International Development'\n",
      " 'International Affairs and Public Health' 'International affairs'\n",
      " 'International Affairs/Business' 'Master of International Affairs'\n",
      " 'International Politics' 'SIPA / MIA'\n",
      " 'International Security Policy - SIPA' 'Intrernational Affairs'\n",
      " 'International Affairs - Economic Policy' 'SIPA - Energy' 'Public Policy'\n",
      " 'Human Rights: Middle East' 'Human Rights' 'SIPA-International Affairs'\n",
      " 'Public Administration']\n",
      "==========\n",
      "Field Code 14.0\n",
      "['Film' 'MFA -Film' 'film']\n",
      "==========\n",
      "Field Code 15.0\n",
      "['Arts Administration' 'Museum Anthropology'\n",
      " 'Theatre Management & Producing' 'MFA Writing' 'MFA  Poetry' 'Theater'\n",
      " 'MFA Acting Program' 'Acting' 'Public Health']\n",
      "==========\n",
      "Field Code 16.0\n",
      "['Polish' 'Japanese Literature' 'french']\n",
      "==========\n",
      "Field Code 17.0\n",
      "['Architecture']\n",
      "==========\n",
      "Field Code 18.0\n",
      "['working' 'GSAS' 'Climate Dynamics']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>...</th>\n",
       "      <th>sinc2_1_f</th>\n",
       "      <th>intel2_1_f</th>\n",
       "      <th>fun2_1_f</th>\n",
       "      <th>amb2_1_f</th>\n",
       "      <th>shar2_1_f</th>\n",
       "      <th>attr3_1_f</th>\n",
       "      <th>sinc3_1_f</th>\n",
       "      <th>fun3_1_f</th>\n",
       "      <th>intel3_1_f</th>\n",
       "      <th>amb3_1_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     match  int_corr  samerace   age  field_cd  mn_sat  tuition  race  \\\n",
       "100      0      0.14         0  27.0       8.0  -999.0   -999.0   2.0   \n",
       "110      0      0.54         0  22.0       1.0  -999.0   -999.0   2.0   \n",
       "120      1      0.16         1  22.0       1.0  -999.0   -999.0   4.0   \n",
       "130      1      0.61         0  23.0       1.0  -999.0   -999.0   2.0   \n",
       "140      1      0.21         0  24.0       1.0  -999.0   -999.0   3.0   \n",
       "\n",
       "     imprace  imprelig    ...     sinc2_1_f  intel2_1_f  fun2_1_f  amb2_1_f  \\\n",
       "100      7.0       3.0    ...          20.0        15.0      20.0       5.0   \n",
       "110      1.0       1.0    ...          20.0        15.0      20.0       5.0   \n",
       "120      3.0       5.0    ...          20.0        15.0      20.0       5.0   \n",
       "130      1.0       1.0    ...          20.0        15.0      20.0       5.0   \n",
       "140      3.0       1.0    ...          20.0        15.0      20.0       5.0   \n",
       "\n",
       "     shar2_1_f  attr3_1_f  sinc3_1_f  fun3_1_f  intel3_1_f  amb3_1_f  \n",
       "100        5.0        6.0        8.0       8.0         8.0       7.0  \n",
       "110        5.0        6.0        8.0       8.0         8.0       7.0  \n",
       "120        5.0        6.0        8.0       8.0         8.0       7.0  \n",
       "130        5.0        6.0        8.0       8.0         8.0       7.0  \n",
       "140        5.0        6.0        8.0       8.0         8.0       7.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHVCAYAAAADyWaQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141e35c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "df = pd.read_csv('speed-dating-experiment/Speed Dating Data.csv')\n",
    "\n",
    "df.shape\n",
    "\n",
    "df = df.iloc[:, :97]\n",
    "df.iid.nunique()\n",
    "df = df.drop(['id'], axis=1)\n",
    "df = df.drop(['idg'], axis=1)\n",
    "\n",
    "df.drop_duplicates(subset=['iid']).gender.value_counts()\n",
    "df.drop_duplicates(subset=['iid']).condtn.value_counts()\n",
    "df = df.drop(['condtn'], axis=1)\n",
    "\n",
    "df.wave.unique()\n",
    "\n",
    "df = df.drop(['round'], axis=1)\n",
    "df = df.drop(['position', 'positin1'], axis=1)\n",
    "\n",
    "\n",
    "df = df.drop(['order'], axis=1)\n",
    "df = df.drop(['partner'], axis=1)\n",
    "df = df.drop(['age_o', 'race_o', 'pf_o_att', \n",
    "              'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "              'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o',\n",
    "              'amb_o', 'shar_o', 'like_o', 'prob_o','met_o'], \n",
    "             axis=1)\n",
    "\n",
    "df.drop_duplicates(subset=['iid']).age.hist(bins=20)\n",
    "\n",
    "df.drop_duplicates('iid').age.isnull().sum()\n",
    "\n",
    "df = df.dropna(subset=['age'])\n",
    "\n",
    "for i, group in df.groupby('field_cd'):\n",
    "    print('=' * 10)\n",
    "    print('Field Code {}'.format(i))\n",
    "    print(group.field.unique())\n",
    "\n",
    "df.field_cd.isnull().sum()\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "df = df.drop(['field'], axis=1)\n",
    "df.undergra.value_counts().head()\n",
    "df = df.drop(['undergra'], axis=1)\n",
    "\n",
    "df.mn_sat.value_counts().head()\n",
    "\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float)\n",
    "df.drop_duplicates('iid').mn_sat.hist()\n",
    "df.drop_duplicates('iid').mn_sat.isnull().sum()\n",
    "\n",
    "df.loc[:, 'mn_sat'] = df.mn_sat.fillna(-999)\n",
    "\n",
    "\n",
    "df.tuition.value_counts().head()\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "df.drop_duplicates('iid').tuition.hist()\n",
    "df.drop_duplicates('iid').tuition.isnull().sum()\n",
    "df.loc[:, 'tuition'] = df.tuition.fillna(-999)\n",
    "\n",
    "df.drop_duplicates('iid').race.value_counts()\n",
    "df.drop_duplicates('iid').age.isnull().sum()\n",
    "df.drop_duplicates('iid').race.hist()\n",
    "df.drop_duplicates('iid').imprace.isnull().sum()\n",
    "df.drop_duplicates('iid').imprelig.isnull().sum()\n",
    "\n",
    "\n",
    "df = df.dropna(subset=['imprelig', 'imprace'])\n",
    "df = df.drop(['from', 'zipcode'], axis=1)\n",
    "\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "df.drop_duplicates('iid').loc[:, 'income'].hist()\n",
    "df.drop_duplicates('iid').loc[:, 'income'].isnull().sum()\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "\n",
    "df.loc[:, 'date'].isnull().sum()\n",
    "\n",
    "df = df.dropna(subset=['date'])\n",
    "df.career_c.isnull().sum()\n",
    "\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)\n",
    "df = df.drop(['career'], axis=1)\n",
    "\n",
    "df.loc[:, ['sports','tvsports','exercise','dining','museums','art','hiking','gaming',\n",
    "       'clubbing','reading','tv','theater','movies','concerts','music','shopping','yoga']\n",
    "      ].isnull().sum()\n",
    "\n",
    "df = df.drop(['sports','tvsports','exercise','dining','museums','art','hiking','gaming',\n",
    "       'clubbing','reading','tv','theater','movies','concerts','music','shopping','yoga'], axis=1)\n",
    "\n",
    "df.drop_duplicates('iid').exphappy.isnull().sum()\n",
    "df.drop_duplicates('iid').expnum.isnull().sum()\n",
    "\n",
    "df = df.drop(['expnum'], axis=1)\n",
    "\n",
    "\n",
    "feat = ['iid', 'wave', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "idx = ((temp.wave < 6) | (temp.wave > 9)) & (temp.totalsum < 99)\n",
    "temp.loc[idx, ]\n",
    "idx = ((temp.wave >= 6) & (temp.wave <= 9))\n",
    "temp.loc[idx, ]\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] = \\\n",
    "(df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "feat = ['iid', 'wave', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "idx = ((temp.wave < 6) | (temp.wave > 9)) & (temp.totalsum < 90) & (temp.totalsum != 0)\n",
    "temp.loc[idx, ]\n",
    "idx = ((temp.wave >= 6) & (temp.wave <= 9))\n",
    "temp.loc[idx, ]\n",
    "\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] = \\\n",
    "(df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T/df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    \n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "    df = df.drop(feat, axis=1)\n",
    "\n",
    "df = df.drop(['wave'], axis=1)\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                                 .drop(['gender'], axis=1)\\\n",
    "                                 .dropna()\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                                   .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\\\n",
    "                                   .dropna()\n",
    "        \n",
    "df_female.columns = df_female.columns + '_f'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'), on = 'pid', how = 'inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis = 1)\n",
    "df_pair.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier()\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 126 ms\n"
     ]
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49853333171046388"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53622019458587489"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63909774436090228"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "f1_score(y_pred=pipeline.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "int_corr      0.075959\n",
      "income_f      0.038975\n",
      "age_f         0.029798\n",
      "amb1_1_f      0.028036\n",
      "attr2_1_f     0.027837\n",
      "field_cd_f    0.027197\n",
      "intel2_1_f    0.026136\n",
      "shar1_1       0.024629\n",
      "date_f        0.024018\n",
      "go_out_f      0.022423\n",
      "dtype: float64\n",
      "MyDecisionTreeClassifier\n",
      "exphappy      0.021395\n",
      "int_corr      0.017227\n",
      "income_f      0.011948\n",
      "age_f         0.008614\n",
      "imprelig      0.008058\n",
      "shar1_1       0.007780\n",
      "samerace      0.006946\n",
      "sinc1_1_f     0.006946\n",
      "field_cd_f    0.006669\n",
      "imprace_f     0.005557\n",
      "dtype: float64\n",
      "0.516031457955\n",
      "0.536220194586\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "my_clf = MyDecisionTreeClassifier()\n",
    "my_clf.fit(X_train, y_train)\n",
    "\n",
    "features_names = df_pair.columns[1:]\n",
    "\n",
    "print('DecisionTreeClassifier')\n",
    "print(pd.Series(index=features_names, data=clf.feature_importances_).sort_values(ascending=False).head(10))\n",
    "print('MyDecisionTreeClassifier')\n",
    "print(pd.Series(index=features_names, data=my_clf.feature_importances_).sort_values(ascending=False).head(10))\n",
    "\n",
    "print(f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro'))\n",
    "print(f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 5, 'criterion': 'entropy', 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "# Speed Dating Data\n",
    "param_dist = {\"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, None], \"min_samples_split\": range(2, 11), \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "gscv = RandomizedSearchCV(RandomForestClassifier(n_estimators=10), param_dist, n_iter=10)\n",
    "gscv.fit(X_train, y_train)\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
